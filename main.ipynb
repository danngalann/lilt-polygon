{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9a3d1309efd32",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409a00d57a0ff8d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096c7b419b6b9d4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets_root = 'datasets'\n",
    "dataset_id = 'FUNSD_polygon_augmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62815d2ce12da1c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "from transformers import LayoutLMv3FeatureExtractor, AutoTokenizer, LayoutLMv3Processor\n",
    "from datasets import Features, Sequence, ClassLabel, Value, Array2D\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1909f5b165b18a88",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load dataset\n",
    "Generate a Dataset object from a generator function that contains the paths of the images and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592bd60aa0a77ee",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_samples(folder):\n",
    "    images_path = Path(folder) / 'images'\n",
    "    annotations_path = Path(folder) / 'annotations'\n",
    "    \n",
    "    images = list(images_path.glob('*.png'))\n",
    "    \n",
    "    for image_path in images:\n",
    "        image_id = image_path.stem\n",
    "        annotation_path = annotations_path / f'{image_id}.json'\n",
    "        yield {\n",
    "            'image_path': str(image_path),\n",
    "            'annotation_path': str(annotation_path)\n",
    "        }\n",
    "\n",
    "def get_features_type():\n",
    "    return Features({\n",
    "        \"image_path\": Value(\"string\"),\n",
    "        \"annotation_path\": Value(\"string\")\n",
    "    })\n",
    "\n",
    "def get_dataset_folder(split='train'):\n",
    "    if split == 'train':\n",
    "        path = Path(datasets_root) / dataset_id / 'dataset' / 'training_data'\n",
    "    elif split == 'test':\n",
    "        path = Path(datasets_root) / dataset_id / 'dataset' / 'testing_data'\n",
    "    else:\n",
    "        raise ValueError('split must be either \"train\" or \"test\"')\n",
    "    \n",
    "    return path\n",
    "\n",
    "\n",
    "\n",
    "train_folder = get_dataset_folder()\n",
    "train_dataset = Dataset.from_generator(partial(generate_samples, train_folder), features=get_features_type())\n",
    "test_folder = get_dataset_folder('test')\n",
    "test_dataset = Dataset.from_generator(partial(generate_samples, test_folder), features=get_features_type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5ba4453385e7a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_unique_labels(folder):\n",
    "    annotations_path = Path(folder) / 'annotations'\n",
    "    unique_labels = set()\n",
    "\n",
    "    for annotation_file in annotations_path.glob('*.json'):\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            annotations = json.load(f)['form']\n",
    "            for annotation in annotations:\n",
    "                unique_labels.add(annotation['label'])\n",
    "\n",
    "    return sorted(list(unique_labels))\n",
    "\n",
    "labels = get_unique_labels(train_folder)\n",
    "num_labels = len(labels)\n",
    "label_to_id = {label: idx for idx, label in enumerate(labels)}\n",
    "id_to_label = {idx: label for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9afc0e7b222553c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Preprocess dataset\n",
    "Load the images and annotations, and encode them using the LayoutLMv3 processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7fb18673b75994",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize processor\n",
    "model_id = \"SCUT-DLVCLab/lilt-roberta-en-base\"\n",
    "feature_extractor = LayoutLMv3FeatureExtractor(apply_ocr=False)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "processor = LayoutLMv3Processor(feature_extractor, tokenizer)\n",
    "\n",
    "# Custom features\n",
    "features = Features(\n",
    "    {\n",
    "        \"input_ids\": Sequence(feature=Value(dtype=\"int64\")),\n",
    "        \"attention_mask\": Sequence(feature=Value(dtype=\"int64\")),\n",
    "        \"polygon\": Array2D(dtype=\"int64\", shape=(512, 8)),\n",
    "        \"labels\": Sequence(feature=ClassLabel(names=labels)),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocess function\n",
    "def process(sample, processor=None):\n",
    "    # Assume sample[\"annotation_path\"] is the path to the JSON file containing your annotations\n",
    "    with open(sample[\"annotation_path\"], \"r\") as f:\n",
    "        annotations = json.load(f)['form']\n",
    "\n",
    "    # Extract sequence and bounding polygons from annotations\n",
    "    sequences = [ann[\"text\"] for ann in annotations]\n",
    "    polygons = [ann[\"polygon\"] for ann in annotations]  # Modify this if your \"polygon\" is not actually a bbox\n",
    "    \n",
    "    max_length = 512\n",
    "    padding_length = max_length - len(sequences)\n",
    "\n",
    "    # Custom Padding for polygons\n",
    "    polygons = polygons + [[0, 0, 0, 0, 0, 0, 0, 0] for _ in range(padding_length)]\n",
    "    \n",
    "    # Custom Padding for sequence\n",
    "    sequences = sequences + [\"[PAD]\" for _ in range(padding_length)]\n",
    "    \n",
    "    # Load image\n",
    "    image = Image.open(sample[\"image_path\"]).convert(\"RGB\")\n",
    "    \n",
    "    # Extract labels for each sequence from annotations\n",
    "    sequence_labels = [label_to_id[ann['label']] for ann in annotations]    \n",
    "    sequence_labels = sequence_labels + [-100 for _ in range(padding_length)]\n",
    "\n",
    "    # Encoding without \n",
    "    encoding = processor(\n",
    "        image,\n",
    "        sequences,\n",
    "        word_labels=sequence_labels,\n",
    "        boxes=polygons,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    # Manually insert polygons (since processor can't handle 8-coordinates)\n",
    "    encoding['polygon'] = polygons\n",
    "    \n",
    "    del encoding[\"pixel_values\"]\n",
    "    del encoding['bbox']\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Process your dataset (replace `dataset` with the actual dataset object)\n",
    "train_dataset = train_dataset.map(\n",
    "    partial(process, processor=processor),\n",
    "    remove_columns=[\"image_path\", \"annotation_path\"],\n",
    "    features=features,\n",
    ").with_format(\"torch\")\n",
    "test_dataset = test_dataset.map(\n",
    "    partial(process, processor=processor),\n",
    "    remove_columns=[\"image_path\", \"annotation_path\"],\n",
    "    features=features,\n",
    ").with_format(\"torch\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a38fe9ea360cf19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a574d7c6e1f5a373",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "dataset = DatasetDict({'train': train_dataset, 'test': test_dataset})\n",
    "dataset.save_to_disk(Path(datasets_root) / dataset_id / 'huggingface_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d424c1bd12716d2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b939a67b23b9717",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load HF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de563222080a89",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "dataset = DatasetDict.load_from_disk(f'{datasets_root}/{dataset_id}/huggingface_dataset')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302cfcb7c774a575",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from model.lilt import  LiltForTokenClassification\n",
    "from transformers import AutoConfig"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df1ed642cad1cba4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cebd70dc102ea1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    'SCUT-DLVCLab/lilt-roberta-en-base',\n",
    "    num_labels=num_labels,\n",
    "    label2id=label_to_id,\n",
    "    id2label=id_to_label,\n",
    "    problem_type=\"single_label_classification\",\n",
    ")\n",
    "# Overriding specific configurations\n",
    "# config.hidden_size = 768\n",
    "# config.max_2d_position_embeddings = 1024\n",
    "# config.channel_shrink_ratio = 2\n",
    "model = LiltForTokenClassification(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2869bc96f0250a3f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prepare metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6cc62d4a480725",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# load seqeval metric\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "# labels of the model\n",
    "class_labels = [config.id2label[i] for i in range(num_labels)]\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(class_labels[predicted_idx])\n",
    "            all_labels.append(class_labels[label_idx])\n",
    "    return metric.compute(predictions=[all_predictions], references=[all_labels])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3062c2f7bebe8a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prepare trainer & train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "repository_id = \"lilt-polygon\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f97233bb6e807ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73cd82e58d3e022",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    fp16=True,\n",
    "    learning_rate=5e-5,\n",
    "    max_steps=1000,\n",
    "    # logging & evaluation strategies\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=200,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"overall_f1\",\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13517dd7da566f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer.train(resume_from_checkpoint = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214dd8f9-7c3c-4400-b3ea-e1486071254e",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load trained model "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "227990cafa246513"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03362c-3aca-4696-b4aa-71e631b56252",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'{repository_id}/checkpoint-200'\n",
    "model = LiltForTokenClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label2color = {label: np.random.randint(0, 255, 3) for label in labels}\n",
    "label2color"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5413f6510d9a25dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def unnormalize_polygon(polygon, width, height):\n",
    "    return [\n",
    "        int(polygon[0] * width),\n",
    "        int(polygon[1] * height),\n",
    "        int(polygon[2] * width),\n",
    "        int(polygon[3] * height),\n",
    "        int(polygon[4] * width),\n",
    "        int(polygon[5] * height),\n",
    "        int(polygon[6] * width),\n",
    "        int(polygon[7] * height),\n",
    "    ]\n",
    "\n",
    "def process_inference(image):\n",
    "    # Encoding without \n",
    "    encoding = processor(\n",
    "        image,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    encoding['polygon'] = encoding['bbox']\n",
    "    del encoding[\"pixel_values\"]\n",
    "    del encoding['bbox']\n",
    "\n",
    "    return encoding\n",
    "\n",
    "def draw_polygons(image, polygons, predictions):\n",
    "    width, height = image.size\n",
    "    normalized_polygons = [unnormalize_polygon(polygon, width, height) for polygon in polygons]\n",
    "\n",
    "    # draw predictions over the image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()\n",
    "    for prediction, polygon in zip(predictions, normalized_polygons):\n",
    "        if prediction == \"O\":\n",
    "            continue\n",
    "        draw.polygon(polygon, outline=label2color[prediction])\n",
    "        draw.text((polygon[0] + 10, polygon[1] - 10), text=prediction, fill=label2color[prediction], font=font)\n",
    "    return image\n",
    "\n",
    "# run inference\n",
    "def run_inference(image, output_image=True):\n",
    "    # create model input\n",
    "    encoding = process_inference(image)\n",
    "    print(encoding[\"polygon\"][0])\n",
    "    # run inference\n",
    "    outputs = model(**encoding)\n",
    "    predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
    "    # get labels\n",
    "    labels = [model.config.id2label[prediction] for prediction in predictions]\n",
    "    if output_image:\n",
    "        return draw_polygons(image, encoding[\"polygon\"][0], labels)\n",
    "    else:\n",
    "        return labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15da79635cbf418a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processor.feature_extractor.apply_ocr = True\n",
    "inference_image = Image.open(test_dataset[0]['image_path']).convert(\"RGB\")\n",
    "res = run_inference(inference_image, False)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83c620164f4f7412"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
